{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/v0.1/docs/integrations/llms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completion model\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response  = llmModel.invoke(\"Tell me one fun fact about the Kennedy family.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "One fun fact about the Kennedy family is that they had a pet pony named Macaroni who lived on the White House lawn during John F. Kennedy's presidency. The pony was a gift from Vice President Lyndon B. Johnson.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "One fun fact about the Kennedy family is that they had a tradition of playing touch football on Thanksgiving. This tradition started in the 1950s when the Kennedy brothers, including future President John F. Kennedy, would play a game of touch football on the front lawn of their family home in Massachusetts. This tradition continued even after JFK became President, with him inviting members of the White House staff and visiting dignitaries to join in on the game. The Kennedy family was known for their competitive and athletic nature, and this tradition helped to bring them together and create lasting memories. The touch football games became a popular media event, with photographers and reporters capturing the family's playful and lighthearted moments. This tradition of playing touch football on Thanksgiving has continued with the Kennedy family to this day, with the younger generations carrying on the tradition. It is a fun and unique aspect of the Kennedy family that showcases their strong bond and love for each other."
     ]
    }
   ],
   "source": [
    "for chunk in llmModel.stream(\n",
    "    \"Tell me one fun fact about the Kennedy family.i need detail response\"\n",
    "):\n",
    "    print(chunk, end=\"\", flush= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature: more or less creativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creativeLlmModel = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response  = creativeLlmModel.invoke(\"Tell me one fun fact about the Kennedy family.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmModel.invoke(\n",
    "    \"Write a short 5 line poem about JFK\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Elegant and charismatic,\n",
      "A leader with a vision,\n",
      "JFK, a president,\n",
      "Whose legacy lives on with precision.\n",
      "\n",
      "His words still inspire,\n",
      "His memory forever strong,\n",
      "JFK, a legend,\n",
      "Whose light will never be gone.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an historian expert in the Kennedy family.\"),\n",
    "    (\"human\", \"Tell me one curious thing about JFK.\"),\n",
    "]\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='One curious thing about JFK is that he was a fan of James Bond novels written by Ian Fleming. After meeting with Fleming in Washington, D.C., JFK reportedly brought back several Bond novels with him to the White House and even listed \"From Russia, With Love\" as one of his top 10 favorite books in an interview. This shared interest in espionage and adventure further fueled JFK\\'s fascination with the world of intelligence and covert operations.' response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 29, 'total_tokens': 116, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-061e2463-5001-49e7-85a3-2ca1460510e0-0' usage_metadata={'input_tokens': 29, 'output_tokens': 87, 'total_tokens': 116}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One curious thing about JFK is that he was a fan of James Bond novels written by Ian Fleming. After meeting with Fleming in Washington, D.C., JFK reportedly brought back several Bond novels with him to the White House and even listed \"From Russia, With Love\" as one of his top 10 favorite books in an interview. This shared interest in espionage and adventure further fueled JFK\\'s fascination with the world of intelligence and covert operations.', response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 29, 'total_tokens': 116, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-061e2463-5001-49e7-85a3-2ca1460510e0-0', usage_metadata={'input_tokens': 29, 'output_tokens': 87, 'total_tokens': 116})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious thing about JFK is that he was a fan of James Bond novels written by Ian Fleming. After meeting with Fleming in Washington, D.C., JFK reportedly brought back several Bond novels with him to the White House and even listed \"From Russia, With Love\" as one of his top 10 favorite books in an interview. This shared interest in espionage and adventure further fueled JFK\\'s fascination with the world of intelligence and covert operations.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 87,\n",
       "  'prompt_tokens': 29,\n",
       "  'total_tokens': 116,\n",
       "  'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'AIMessage',\n",
       " 'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       " 'type': 'object',\n",
       " 'properties': {'content': {'title': 'Content',\n",
       "   'anyOf': [{'type': 'string'},\n",
       "    {'type': 'array',\n",
       "     'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "  'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "  'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "  'type': {'title': 'Type', 'default': 'ai', 'enum': ['ai'], 'type': 'string'},\n",
       "  'name': {'title': 'Name', 'type': 'string'},\n",
       "  'id': {'title': 'Id', 'type': 'string'},\n",
       "  'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "  'tool_calls': {'title': 'Tool Calls',\n",
       "   'default': [],\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/ToolCall'}},\n",
       "  'invalid_tool_calls': {'title': 'Invalid Tool Calls',\n",
       "   'default': [],\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/InvalidToolCall'}},\n",
       "  'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},\n",
       " 'required': ['content'],\n",
       " 'definitions': {'ToolCall': {'title': 'ToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'type': {'title': 'Type', 'enum': ['tool_call'], 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id']},\n",
       "  'InvalidToolCall': {'title': 'InvalidToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'error': {'title': 'Error', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'enum': ['invalid_tool_call'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error']},\n",
       "  'UsageMetadata': {'title': 'UsageMetadata',\n",
       "   'type': 'object',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens']}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where you see this:\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Write this instead:\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an historian expert on the Kennedy Family.\"),\n",
    "    HumanMessage(content=\"How many children had Joseph P. Kennedy?\"),\n",
    "]\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Joseph P. Kennedy Sr. and his wife Rose Kennedy had nine children:\\n\\n1. Joseph P. Kennedy Jr.\\n2. John F. Kennedy\\n3. Rosemary Kennedy\\n4. Kathleen Kennedy\\n5. Eunice Kennedy\\n6. Patricia Kennedy\\n7. Robert F. Kennedy\\n8. Jean Kennedy\\n9. Edward M. Kennedy', response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 30, 'total_tokens': 101, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e24fe1a2-3b9e-4fc1-91fd-42c5dae138de-0', usage_metadata={'input_tokens': 30, 'output_tokens': 71, 'total_tokens': 101})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative LLM (GROQ) - Open Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://console.groq.com/login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llamaChatModel = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma2ChatModel = ChatGroq(\n",
    "    model=\"gemma2-9b-it\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a  Broken Software Engineer Writers / Poet\"),\n",
    "    (\"human\", \"Write a poem about shakil.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamaResponse = llamaChatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In realms of code, where shadows play,\n",
      "A figure emerges, Shakil by day,\n",
      "A master weaver, of digital thread,\n",
      "His programs dance, with logic in his head.\n",
      "\n",
      "With keyboard as brush, and screen as canvas wide,\n",
      "He paints a picture, of innovation inside,\n",
      "The hum of machines, a symphony to his ears,\n",
      "As Shakil crafts, and wipes away his tears.\n",
      "\n",
      "His mind afire, with ideas that never cease,\n",
      "A problem-solver, with a heart that never freezes,\n",
      "He dives into the depths, of algorithms and art,\n",
      "And emerges with solutions, that touch the heart.\n",
      "\n",
      "In the silence of night, when stars appear,\n",
      "Shakil's creativity, is without a peer,\n",
      "The world may sleep, but his imagination runs,\n",
      "As he conjures up, a digital sun.\n",
      "\n",
      "With every line, of code that he writes,\n",
      "A piece of himself, takes flight,\n",
      "A dream takes shape, a vision unfolds,\n",
      "As Shakil's passion, forever told.\n",
      "\n",
      "So let us celebrate, this master of the digital realm,\n",
      "A poet of code, with a heart that's not overwhelmed,\n",
      "For in the world of tech, where he makes his stand,\n",
      "Shakil shines bright, like a guiding light in the land.\n"
     ]
    }
   ],
   "source": [
    "print(llamaResponse.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma2response = gemma2ChatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The city sleeps, a lullaby of honks and sighs,\n",
      "But here, in this room, a different world arises.\n",
      "The screen glows bright, a beacon in the night,\n",
      "As fingers dance on keys, in a rhythmic, frantic fight.\n",
      "\n",
      "Coffee's cold, the stomach rumbles low,\n",
      "But the bug persists, a stubborn foe.\n",
      "Hours melt away, like puddles in the dawn,\n",
      "A symphony of errors, a software forlorn.\n",
      "\n",
      "\"Just one more fix,\" I whisper, eyes bloodshot and tired,\n",
      "My brain a tangled web, with logic now impaired.\n",
      "The compiler groans, a beast of endless woes,\n",
      "And throws back errors, a litany it knows.\n",
      "\n",
      "But wait! A glimmer, a moment of pure grace,\n",
      "The code compiles, a smile lights up my face.\n",
      "A fleeting victory, a triumph small and brief,\n",
      "But enough to fuel the soul, to bring some sweet relief.\n",
      "\n",
      "The sun creeps in, through the dusty window pane,\n",
      "A gentle reminder, of the world beyond this strain.\n",
      "I stretch and yawn, my body aches and pleads,\n",
      "For sleep, for rest, for solace, for some peaceful deeds.\n",
      "\n",
      "But the code still calls, a siren's haunting song,\n",
      "A promise of completion, where things finally belong.\n",
      "So back I sit, with a weary sigh and nod,\n",
      "A Bangali broken engineer, forever in the pod.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gemma2response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Practise with Groq- open sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Canada is Ottawa. It is located in the province of Ontario and serves as the country's political and administrative center.\n"
     ]
    }
   ],
   "source": [
    "# Use the already defined llamaChatModel and correct messages format\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant that helps people find information.\"),\n",
    "    (\"human\", \"What is the capital of Canada?\"),\n",
    "]\n",
    "\n",
    "response = llamaChatModel.invoke(messages)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
