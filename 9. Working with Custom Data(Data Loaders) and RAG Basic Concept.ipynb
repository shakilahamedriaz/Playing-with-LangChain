{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00de9a1",
   "metadata": {},
   "source": [
    "## üëâ Working with your own data (via Data Loaders)\n",
    "## üëâ Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1992906",
   "metadata": {},
   "source": [
    "# Agenda:\n",
    "1. Data loader - how to work with custom data\n",
    "2. Introduction to RAG - Retrival Augmented Generation\n",
    "3. Spiltters\n",
    "4. Embeddings\n",
    "5. Vector Store\n",
    "6. Retriver\n",
    "7. Top K\n",
    "\n",
    "Next: RAG with LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e964a",
   "metadata": {},
   "source": [
    "### üîπ 1. Working with Custom Data (Data Loaders)\n",
    "\n",
    "LLMs like GPT are powerful, but they don‚Äôt know your private PDFs, docs, or DBs.\n",
    "So LangChain gives us Document Loaders to bring your own data inside.\n",
    "\n",
    "‚ú® Steps:\n",
    "\n",
    "Load data (PDF, TXT, CSV, URL, DB, JSOn etc.)\n",
    "\n",
    "Split into chunks (LLMs can‚Äôt handle huge docs at once).\n",
    "\n",
    "Store in a Vector Database (for similarity search).\n",
    "\n",
    "Use RAG pipeline ‚Üí ask questions over your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efc2aaa",
   "metadata": {},
   "source": [
    "#### Example: Loading a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505ee1c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 1. Load your PDF\u001b[39;00m\n\u001b[32m      4\u001b[39m loader = PyPDFLoader(\u001b[33m\"\u001b[39m\u001b[33msample.pdf\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 1. Load your PDF\n",
    "loader = PyPDFLoader(\"sample.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[0].page_content[:500])  # See first 500 chars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c10f14e",
   "metadata": {},
   "source": [
    "#### Example: Splitting Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b69eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "print(len(chunks))\n",
    "print(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0107f",
   "metadata": {},
   "source": [
    "### üîπ 2. RAG (Retrieval-Augmented Generation) ‚Äî Basic Concept\n",
    "\n",
    "Problem: LLMs often \"hallucinate\" (make up answers).\n",
    "Solution: Instead of relying only on the model‚Äôs memory ‚Üí give it retrieved data from your documents.\n",
    "\n",
    "‚ú® How RAG Works\n",
    "\n",
    "User Question ‚Üí \"What is space weather?\"\n",
    "\n",
    "Retriever (Vector DB) finds relevant chunks from your docs.\n",
    "\n",
    "LLM combines both (prompt + retrieved data) to give grounded answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62498b6b",
   "metadata": {},
   "source": [
    "#### üîπ Simple RAG Example with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd53ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 1. Embeddings (turn text into vectors)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 2. Store in FAISS (local vector DB)\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "# 3. Retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 4. RAG Chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "qa = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "\n",
    "# 5. Ask Question\n",
    "query = \"Summarize this document in 3 bullet points.\"\n",
    "result = qa.run(query)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493c3e8b",
   "metadata": {},
   "source": [
    "üîπ Key Idea:\n",
    "\n",
    "Without RAG ‚Üí Model answers from its own knowledge (may be outdated/wrong).\n",
    "\n",
    "With RAG ‚Üí Model answers from your documents (reliable, context-aware).\n",
    "\n",
    "‚úÖ You can use loaders for:\n",
    "\n",
    "PDFs ‚Üí PyPDFLoader\n",
    "\n",
    "Word Docs ‚Üí Docx2txtLoader\n",
    "\n",
    "Websites ‚Üí WebBaseLoader\n",
    "\n",
    "Notion, Slack, DBs ‚Üí Special loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f3acc",
   "metadata": {},
   "source": [
    "# MCP Server (letter we will leran)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5217588",
   "metadata": {},
   "source": [
    "\n",
    "MCP server ‡¶®‡¶ø‡ßü‡ßá ‡¶è‡¶ï‡¶ü‡¶æ **‡¶∏‡¶π‡¶ú ‡¶õ‡ßã‡¶ü ‡¶®‡ßã‡¶ü‡¶∏** ‡¶¨‡¶æ‡¶®‡¶æ‡¶á‚Äî‡¶Ø‡¶æ‡¶§‡ßá ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ ‡¶™‡ßú‡¶≤‡ßá ‡¶™‡¶∞‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∞ ‡¶Ü‡¶á‡¶°‡¶ø‡ßü‡¶æ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü‡•§\n",
    "\n",
    "---\n",
    "\n",
    "# üìí Easy Notes on MCP Server\n",
    "\n",
    "### üîπ What is MCP Server?\n",
    "\n",
    "üëâ **MCP (Model Context Protocol) server = ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞‡¶ø ‡¶ú‡¶æ‡ßü‡¶ó‡¶æ ‡¶•‡ßá‡¶ï‡ßá ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞‡¶ø ‡¶§‡¶•‡ßç‡¶Ø ‡¶è‡¶®‡ßá LLM ‡¶ï‡ßá ‡¶ñ‡¶æ‡¶ì‡ßü‡¶æ‡¶®‡ßã‡•§**\n",
    "‡¶è‡¶ü‡¶æ basically ‡¶è‡¶ï ‡¶ß‡¶∞‡¶®‡ßá‡¶∞ **middle layer**, ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá LLM ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶∏‡¶¨ data ‡¶¨‡¶æ API access ‡¶®‡¶æ ‡¶ï‡¶∞‡ßá MCP server ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá data ‡¶®‡ßá‡ßü‡•§\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Why MCP Server?\n",
    "\n",
    "* LLM ‡¶∏‡¶¨‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶ú‡¶æ‡¶®‡ßá ‡¶®‡¶æ ‚Üí ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ knowledge ‡¶è ‡¶∏‡ßÄ‡¶Æ‡¶æ‡¶¨‡¶¶‡ßç‡¶ß‡•§\n",
    "* Custom data / company data ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ ‡¶π‡¶≤‡ßá MCP ‡¶¶‡¶ø‡ßü‡ßá ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶π‡ßü‡•§\n",
    "* ‡¶®‡¶ø‡¶∞‡¶æ‡¶™‡¶¶, ‡¶ï‡¶æ‡¶∞‡¶£ LLM ‡¶ï‡ßá direct DB/API access ‡¶¶‡¶ø‡¶§‡ßá ‡¶π‡ßü ‡¶®‡¶æ‡•§\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ How it Works (Flow)\n",
    "\n",
    "1. **User ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ï‡¶∞‡ßá** ‚Üí e.g., ‚ÄúRemote work policy ‡¶ï‡ßÄ?‚Äù\n",
    "2. **LLM Agent** ‚Üí MCP server ‡¶ï‡ßá call ‡¶ï‡¶∞‡ßá‡•§\n",
    "3. **MCP Server** ‚Üí relevant system/doc (PDF, DB, API) ‡¶•‡ßá‡¶ï‡ßá info ‡¶Ü‡¶®‡ßá‡•§\n",
    "4. **LLM** ‚Üí ‡¶∏‡ßá‡¶á data ‡¶¶‡¶ø‡ßü‡ßá answer generate ‡¶ï‡¶∞‡ßá‡•§\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Example Use Cases\n",
    "\n",
    "* **HR Policies** ‚Üí Employee handbook ‡¶•‡ßá‡¶ï‡ßá policy ‡¶Ü‡¶®‡¶æ‡•§\n",
    "* **Customer Support** ‚Üí CRM ‡¶•‡ßá‡¶ï‡ßá customer history ‡¶Ü‡¶®‡¶æ‡•§\n",
    "* **Finance** ‚Üí Payroll ‡¶¨‡¶æ invoice DB ‡¶•‡ßá‡¶ï‡ßá ‡¶§‡¶•‡ßç‡¶Ø ‡¶Ü‡¶®‡¶æ‡•§\n",
    "* **DevOps** ‚Üí Server health check ‡¶¨‡¶æ logs ‡¶Ü‡¶®‡¶æ‡•§\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Benefits\n",
    "\n",
    "‚úÖ **Grounded Answer** ‚Üí hallucination ‡¶ï‡¶Æ‡ßá‡•§\n",
    "‚úÖ **Standardized Access** ‚Üí ‡¶∏‡¶¨ data source ‡¶è ‡¶è‡¶ï format ‡¶è access‡•§\n",
    "‚úÖ **Security** ‚Üí ‡¶∏‡ßÄ‡¶Æ‡¶ø‡¶§ access control‡•§\n",
    "‚úÖ **Reusable** ‚Üí ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ MCP ‡¶¨‡¶æ‡¶®‡¶æ‡¶≤‡ßá agent ‡¶∏‡¶π‡¶ú‡ßá use ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Relation with RAG\n",
    "\n",
    "* **RAG** = ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ data (PDF, Docs, DB) ‡¶•‡ßá‡¶ï‡ßá answer ‡¶¨‡¶æ‡¶®‡¶æ‡¶®‡ßã‡•§\n",
    "* **MCP** = ‡¶∏‡ßá‡¶á retriever / tool ‡¶ï‡ßá ‡¶è‡¶ï‡¶ü‡¶æ **standard server** ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá expose ‡¶ï‡¶∞‡¶æ‡•§\n",
    "\n",
    "üëâ ‡¶¨‡¶≤‡¶æ ‡¶Ø‡¶æ‡ßü:\n",
    "**RAG = concept** (retrieve + generate)\n",
    "**MCP = technology** (standard way to serve data/tools to LLM)\n",
    "\n",
    "---\n",
    "\n",
    "# üìù Quick Summary\n",
    "\n",
    "* **MCP server = middleman** ‚Üí LLM ‚Üî Data/API.\n",
    "* **Job** ‚Üí ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞‡¶ø ‡¶§‡¶•‡ßç‡¶Ø ‡¶è‡¶®‡ßá ‡¶¶‡ßá‡¶ì‡ßü‡¶æ‡•§\n",
    "* **Use Cases** ‚Üí HR, Finance, Support, DevOps, Knowledge base.\n",
    "* **Benefit** ‚Üí safe, reusable, no hallucination, standardized.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
